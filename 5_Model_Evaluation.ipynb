{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[SJ] Model Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhAJ+s5vx8UXbqizpToyFd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sejin-sim/Data_Mining/blob/main/5_Model_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqmcYpEt8cID"
      },
      "source": [
        "# * Problems for evaluation\n",
        "\n",
        "1. Metrics for Performance Evaluation (평가 척도)\n",
        "  - How to evaluate the performance of a model?\n",
        "2. Methods for Performance Evaluation (평가 방법)\n",
        "  - How to obtain reliable estimates?\n",
        "3. Methods for Model Comparison (모델 비교)\n",
        "  - How to compare the relative performance among competing models?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaronfjG83qO"
      },
      "source": [
        "### Classification Accuracy   \n",
        "– Classification accuracy is the number of correct predictions made as a ratio of all predictions made.   \n",
        "– the most common evaluation metric for classification problems, it is also the most misused.   \n",
        "  - 각 class(합격, 불합격)가 등등하게 구성된 경우에 적당"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EevOEwLZ8YBN",
        "outputId": "df209ac4-24c9-4ba8-9762-703bf7c754e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "# Cross Validation Classification Accuracy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "df = pandas.read_csv(url, names=names)\n",
        "display(df)\n",
        "array = dataframe.values\n",
        "\n",
        "X = df.drop(['class'], axis=\"columns\")\n",
        "Y = df['class']\n",
        "\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=7) # 분할 파라미터\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring='accuracy') # 교차 검증\n",
        "# results : 분할 검증 10개의 검증 값\n",
        "\n",
        "print(\"* Accuracy(K-FOLD=10, LR 예측시)\\n\", \"1. 분할검증의 평균 값 :\", results.mean(), \"\\n\",  \"2. 분할검증의 표준 편차 :\", results.std())\n",
        "\n",
        "# - 각 표본들의 평균과 전체 평균 간의 간격\n",
        "# - 표준오차가 작을수록 표본의 대표성이 높다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preg</th>\n",
              "      <th>plas</th>\n",
              "      <th>pres</th>\n",
              "      <th>skin</th>\n",
              "      <th>test</th>\n",
              "      <th>mass</th>\n",
              "      <th>pedi</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>768 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     preg  plas  pres  skin  test  mass   pedi  age  class\n",
              "0       6   148    72    35     0  33.6  0.627   50      1\n",
              "1       1    85    66    29     0  26.6  0.351   31      0\n",
              "2       8   183    64     0     0  23.3  0.672   32      1\n",
              "3       1    89    66    23    94  28.1  0.167   21      0\n",
              "4       0   137    40    35   168  43.1  2.288   33      1\n",
              "..    ...   ...   ...   ...   ...   ...    ...  ...    ...\n",
              "763    10   101    76    48   180  32.9  0.171   63      0\n",
              "764     2   122    70    27     0  36.8  0.340   27      0\n",
              "765     5   121    72    23   112  26.2  0.245   30      0\n",
              "766     1   126    60     0     0  30.1  0.349   47      1\n",
              "767     1    93    70    31     0  30.4  0.315   23      0\n",
              "\n",
              "[768 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "* Accuracy(K-FOLD=10, LR 예측시)\n",
            " 1. 분할검증의 평균 값 : 0.7721633629528366 \n",
            " 2. 분할검증의 표준 편차 : 0.0496837651757489\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt91L0lTDOwP"
      },
      "source": [
        "### - Confusion Matrix\n",
        "\n",
        "(Some example)   \n",
        " - False Positive (FP):   \n",
        "   - 스팸 메일이 아닌데 (spam email=No) 스팸 메일로 처리하는 경우\n",
        "   - 임신이 아닌 데(pregnant=NO) 임신으로 판단하는 경우\n",
        " - False Negative (FN):\n",
        "   - 스팸 메일을 (spam email=Yes) 정상 메일로 처리하는 경우\n",
        "   - 임신인데 (pregnant=Yes) 임신이 아닌 것으로 판단하는 경우\n",
        "\n",
        " \n",
        "<img src=\"https://2.bp.blogspot.com/-uCi_IXC-5C0/W4lDTCG8SnI/AAAAAAAABIo/kxasPdWoA107m1qazYXvHsCy6Q9h1QBSwCEwYBhgL/s1600/xxx.png\"  width=\"700\" height=\"300\">\n",
        "\n",
        "1. Precision(정밀도=정답률) : True라고 분류한 것 중에서 실제 True인 것의 비율\n",
        "2. Accuracy(정확도) : True를 True, False를 False 예측한 경우\n",
        "3. F1-Score : Precision과 Recall의 조화평균\n",
        "4. Recall(재현율) : 실제 True인 것 중에서 모델이 True라고 예측한 것의 비율\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxw0fidPFIci",
        "outputId": "647ddf51-5b72-4705-9806-41089a3a7058",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Cross Validation Classification Confusion Matrix\n",
        "\n",
        "import pandas\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "df = pandas.read_csv(url, names=names)\n",
        "\n",
        "X = df.drop(['class'], axis=\"columns\")\n",
        "Y = df['class']\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, Y_train)\n",
        "predicted = model.predict(X_test)\n",
        "\n",
        "matrix = confusion_matrix(Y_test, predicted)\n",
        "print(matrix)\n",
        "print(\"TP\", \"FP\" ,\"\\n\", \"FN\", \"FP\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[142  20]\n",
            " [ 34  58]]\n",
            "TP FP \n",
            " FN FP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UwrI7FkGL7a",
        "outputId": "dfd6e605-d3d2-46b9-a1d2-07ee28ab9d1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "df = pandas.read_csv(url, names=names)\n",
        "\n",
        "X = df.drop(['class'], axis=\"columns\")\n",
        "Y = df['class']\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, Y_train)\n",
        "predicted = model.predict(X_test)\n",
        "\n",
        "report = classification_report(Y_test, predicted)\n",
        "print(report)\n",
        "\n",
        "# Precision:\n",
        "# 결과에서 class 0.0 이라고 예측한 데이터의81%만이 실제 0.0이었고\n",
        "# 1.0이라고 예측한 데이터의74%만 실제 1.0이었음을나타낸다.\n",
        "\n",
        "# Recall:\n",
        "# 실제 0인 데이터 중의 88%만 0으로 판별되었고\n",
        "# 실제 1인 데이터 중의 63%만 1로 판별되었음을 알 수 있다.\n",
        "\n",
        "# Y_test에서 Class 0.0에 해당하는 개수가 162개\n",
        "# Y_test에서 Class 1.0에 해당하는 개수가 92 개"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.88      0.84       162\n",
            "           1       0.74      0.63      0.68        92\n",
            "\n",
            "    accuracy                           0.79       254\n",
            "   macro avg       0.78      0.75      0.76       254\n",
            "weighted avg       0.78      0.79      0.78       254\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULGDrqi7pU4z"
      },
      "source": [
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbsYNGz%2FbtqEQ6HZtvj%2FUYWpnOt7JcKQKcHXovM9z1%2Fimg.png\"  width=\"700\" height=\"500\">\n",
        "\n",
        "### 1. MAE(Mean Absolute Error) : 모델의 예측값과 실제값의 차이를 모두 더한다는 개념   \n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F67cbb%2FbtqEHN3DQoh%2FdO5cZButYilYN3dLoTCzD0%2Fimg.png\">  \n",
        "- 절대값을 취하기 때문에 모델이 underperformance 인지 overperformance 인지 알 수 없다.\n",
        "  - underperformance: 모델이 실제보다 낮은 값으로 예측\n",
        "  - overperformance: 모델이 실제보다 높은 값으로 예측   \n",
        "\n",
        "\n",
        "### 2. MSE (Mean Squared Error) : 모델의 예측값과 실제값 차이의 면적의 합   \n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbiXfUQ%2FbtqEK604oAE%2FKklZoIfsUc7xImmPOV2Hmk%2Fimg.png\">  \n",
        "- 특이치에 민감하다\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyH1LgKBjK0Q",
        "outputId": "b4fa9efe-b75d-4fba-a868-fc7e72e2f1cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Regression Metrics: Mean Absolute Error(MAE)\n",
        "\n",
        "import pandas\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "df = pandas.read_csv(url, names=names)\n",
        "\n",
        "X = df.drop(['class'], axis=\"columns\")\n",
        "Y = df['class']\n",
        "\n",
        "test_size = 0.33\n",
        "kfold = model_selection.KFold(n_splits=10)\n",
        "model = LogisticRegression(max_iter=500)\n",
        "\n",
        "scoring = 'neg_mean_absolute_error'\n",
        "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "\n",
        "print(\"MAE: \", results.mean(), \"Std: \", results.std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE:  -0.22395762132604236 Std:  0.05157545262086822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBRgfIRTjlRR",
        "outputId": "e620297a-0ccf-4c61-fba7-d1ace13cf57f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Regression Metrics: Mean Squared Error(MSE)\n",
        "\n",
        "import pandas\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "df = pandas.read_csv(url, names=names)\n",
        "\n",
        "X = df.drop(['class'], axis=\"columns\")\n",
        "Y = df['class']\n",
        "\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.33, random_state=7)\n",
        "\n",
        "model = LogisticRegression(max_iter=500)\n",
        "model.fit(X_train, Y_train)\n",
        "predicted = model.predict(X_test)\n",
        "mean_squared_error(Y_test, predicted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2125984251968504"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOonXa5dtvlO"
      },
      "source": [
        "### - ROC (Receiver Operating Characteristic)\n",
        "\n",
        "- (TP, FP):\n",
        "  - (0,0): declare everything to be negative class\n",
        "  - (1,1): declare everything to be positive class\n",
        "  - (1,0): ideal\n",
        "\n",
        "> <img src=\"https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-08-05-ROC/pic1.png\" width=\"500\" height=\"400\">  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv7L6wnGvCXN",
        "outputId": "7c621958-92d3-43d4-9f33-167c83d31d4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Cross Validation Classification ROC AUC\n",
        "import pandas\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "df = pandas.read_csv(url, names=names)\n",
        "\n",
        "X = df.drop(['class'], axis=\"columns\")\n",
        "Y = df['class']\n",
        "\n",
        "kfold = model_selection.KFold(n_splits=10)\n",
        "model = LogisticRegression(max_iter=500)\n",
        "\n",
        "scoring = 'roc_auc'\n",
        "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "\n",
        "print(\"AUC:\", results.mean(), \"std:\", results.std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.8280337127246062 std: 0.04287108616940878\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}